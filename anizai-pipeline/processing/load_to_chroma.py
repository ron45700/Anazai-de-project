import json
import os
import sys
import time

# --- ×”×’×“×¨×ª × ×ª×™×‘×™× ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from services.embedding_service import get_text_embedding
from services.vector_store import VectorStore

INPUT_FILE = os.path.join(BASE_DIR, 'data', 'processed', 'processed_news.json')

def load_data():
    print("ğŸš€ Starting ingestion to ChromaDB...")
    
    # 1. ××ª×—×•×œ ×”××¡×“
    store = VectorStore()
    
    # 2. ×§×¨×™××ª ×”× ×ª×•× ×™×
    if not os.path.exists(INPUT_FILE):
        print("âŒ File not found!")
        return

    count = 0
    success_count = 0
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            count += 1
            try:
                article = json.loads(line)
                
                # ×‘×“×™×§×” ×× ×”×›×ª×‘×” ×›×‘×¨ ×§×™×™××ª (××•×¤×¦×™×•× ×œ×™, ××‘×œ ×—×›×)
                # ×›×¨×’×¢ × ×¡××•×š ×¢×œ Chroma ×©×™×¢×“×›×Ÿ ×× ×”××–×”×” ×§×™×™×
                
                # 3. ×”×›× ×ª ×”×˜×§×¡×˜ ×œ×—×™×¤×•×© (Embedding)
                # ×× ×—× ×• ××—×‘×¨×™× ××ª ×›×œ ×”××™×“×¢ ×”×—×©×•×‘ ×œ×˜×§×¡×˜ ××—×“
                title = article.get('title', '')
                desc = article.get('description', '')
                summary = article.get('processing', {}).get('summary', '')
                
                # ×”×˜×§×¡×˜ ×”××œ× ×©×™×™×›× ×¡ ×œ×—×™×¤×•×©
                combined_text = f"Title: {title}. Description: {desc}. Summary: {summary}"
                
                # ×™×¦×™×¨×ª ×”×•×§×˜×•×¨
                vector = get_text_embedding(combined_text)
                
                if vector:
                    # 4. ×”×›× ×ª ×”××˜×-×“××˜×” (××™×“×¢ × ×œ×•×•×” ×œ×©×œ×™×¤×”)
                    metadata = {
                        "source": article.get('source', {}).get('publisher', 'Unknown'),
                        "published_at": article.get('timestamps', {}).get('published_at', ''),
                        "sentiment": article.get('metadata', {}).get('sentiment', 'Neutral'),
                        "reliability": article.get('metadata', {}).get('reliability_score', 0.5)
                    }
                    
                    # 5. ×©××™×¨×” ×œ××¡×“
                    store.add_article(
                        article_id=article['article_id'],
                        text=combined_text, # ×©×•××¨×™× ××ª ×”×˜×§×¡×˜ ×›×“×™ ×©× ×•×›×œ ×œ×§×¨×•× ××•×ª×• ×‘×ª×•×¦××•×ª
                        embedding=vector,
                        metadata=metadata
                    )
                    success_count += 1
                    print(f"âœ… Added: {title[:30]}...")
                
                # ×”×©×”×™×™×” ×§×˜× ×” ×›×“×™ ×œ× ×œ×”×¤×¦×™×¥ ××ª OpenAI (Rate Limit)
                time.sleep(0.2) 

            except Exception as e:
                print(f"âš ï¸ Failed line {count}: {e}")

    print(f"\nğŸ Finished! Loaded {success_count}/{count} articles into ChromaDB.")
    print(f"ğŸ“Š Total documents in DB: {store.collection.count()}")

if __name__ == "__main__":
    load_data()